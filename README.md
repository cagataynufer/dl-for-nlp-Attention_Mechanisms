# dl-for-nlp-Attention_Mechanisms
This project focuses on implementing various attention mechanisms for NLP tasks, including Bahdanau and Luong attention models, within sequence-to-sequence frameworks.
